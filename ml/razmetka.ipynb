{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7041528,"sourceType":"datasetVersion","datasetId":4049180},{"sourceId":7048093,"sourceType":"datasetVersion","datasetId":4055850}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install huggingsound\n!pip install -U transformers\n!pip install -q ipython-autotime\n!pip install -q accelerate optimum\n!pip install moviepy\n!pip install langchain\n!pip install chromadb\n!pip install sentence-transformers\n!pip install imutils\n!pip install llama-cpp-python\n!pip install faiss-cpu\n!pip install langchain-experimental\n!pip install yandexcloud","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T05:39:39.092583Z","iopub.execute_input":"2023-11-25T05:39:39.092853Z","iopub.status.idle":"2023-11-25T05:45:16.195640Z","shell.execute_reply.started":"2023-11-25T05:39:39.092829Z","shell.execute_reply":"2023-11-25T05:45:16.194236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ~\n!git clone --recursive https://github.com/ggerganov/llama.cpp.git\n%cd llama.cpp\n!make LLAMA_CUBLAS=1 -j libllama.so\n\n# HACK: Use custom compiled libllama.so\n%cp ~/llama.cpp/libllama.so /opt/conda/lib/python3.10/site-packages/llama_cpp/libllama.so","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:45:16.198231Z","iopub.execute_input":"2023-11-25T05:45:16.198555Z","iopub.status.idle":"2023-11-25T05:45:40.548203Z","shell.execute_reply.started":"2023-11-25T05:45:16.198523Z","shell.execute_reply":"2023-11-25T05:45:40.547028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport librosa\nimport time\nimport cv2\nimport imutils\nimport shutil\nimport glob\nimport argparse\n\nimport numpy as np\n\nfrom collections import defaultdict\nfrom pydub import AudioSegment\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    GenerationConfig,\n    Speech2TextProcessor,\n    Speech2TextForConditionalGeneration,\n    Wav2Vec2ForCTC,\n    Wav2Vec2Processor,\n    AutoModelForSpeechSeq2Seq, \n    AutoProcessor, \n    pipeline\n)\nfrom datasets import load_dataset\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.vectorstores import Chroma\nfrom langchain.vectorstores import FAISS\nfrom langchain.callbacks.manager import CallbackManagerForLLMRun\nfrom langchain.llms.base import LLM\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.docstore.document import Document\nfrom chromadb.config import Settings\nfrom llama_cpp import Llama\n\nfrom langchain.agents import Tool\nfrom langchain.agents import load_tools\nfrom langchain.agents import initialize_agent\nfrom langchain.agents import AgentType\nfrom typing import Any, List, Mapping, Optional\nfrom langchain_experimental.agents.agent_toolkits import create_csv_agent\nimport pandas as pd\nfrom tqdm import tqdm\nimport json\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:45:40.549639Z","iopub.execute_input":"2023-11-25T05:45:40.549950Z","iopub.status.idle":"2023-11-25T05:46:01.703575Z","shell.execute_reply.started":"2023-11-25T05:45:40.549920Z","shell.execute_reply":"2023-11-25T05:46:01.702722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:46:01.704663Z","iopub.execute_input":"2023-11-25T05:46:01.705250Z","iopub.status.idle":"2023-11-25T05:46:02.019644Z","shell.execute_reply.started":"2023-11-25T05:46:01.705222Z","shell.execute_reply":"2023-11-25T05:46:02.018688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/\n!mkdir tmp\n%cd tmp\n\n!wget https://huggingface.co/IlyaGusev/saiga_mistral_7b_gguf/resolve/main/model-q4_K.gguf","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:46:02.022143Z","iopub.execute_input":"2023-11-25T05:46:02.022476Z","iopub.status.idle":"2023-11-25T05:46:29.913643Z","shell.execute_reply.started":"2023-11-25T05:46:02.022450Z","shell.execute_reply":"2023-11-25T05:46:29.912519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRANSCRIBER_ID = \"openai/whisper-large-v2\"\n\n# EMBEDDER_ID = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\nEMBEDDER_ID =\"ai-forever/sbert_large_nlu_ru\"\n\n\nFRAME_RATE = 1        \nWARMUP = FRAME_RATE              \nFGBG_HISTORY = round(FRAME_RATE * 15)   \nVAR_THRESHOLD = 16              \nMIN_PERCENT = 0.1               \nMAX_PERCENT = 3         \n\nSYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\"\nSYSTEM_TOKEN = 1587\nUSER_TOKEN = 2188\nBOT_TOKEN = 12435\nLINEBREAK_TOKEN = 13\n\n\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nTORCH_DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32\n\nprint(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:46:29.915011Z","iopub.execute_input":"2023-11-25T05:46:29.915333Z","iopub.status.idle":"2023-11-25T05:46:29.923913Z","shell.execute_reply.started":"2023-11-25T05:46:29.915303Z","shell.execute_reply":"2023-11-25T05:46:29.923048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# openai/whisper-large-v2  \nprocessor = AutoProcessor.from_pretrained(TRANSCRIBER_ID)\nmodel_t = AutoModelForSpeechSeq2Seq.from_pretrained(\n    TRANSCRIBER_ID, torch_dtype=TORCH_DTYPE, low_cpu_mem_usage=True, use_safetensors=True\n)\nmodel_t.to(DEVICE)\n\npipe = pipeline(\n    \"automatic-speech-recognition\",\n    model=model_t,\n    tokenizer=processor.tokenizer,\n    feature_extractor=processor.feature_extractor,\n    max_new_tokens=128,\n    chunk_length_s=30,\n    batch_size=16,\n    return_timestamps=True,\n    torch_dtype=TORCH_DTYPE,\n    device=DEVICE,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:46:29.925130Z","iopub.execute_input":"2023-11-25T05:46:29.925438Z","iopub.status.idle":"2023-11-25T05:47:18.998953Z","shell.execute_reply.started":"2023-11-25T05:46:29.925414Z","shell.execute_reply":"2023-11-25T05:47:18.997732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = HuggingFaceEmbeddings(model_name=EMBEDDER_ID)\n\n# landchain \ndef sliding_window(lst, window_size, step_size):\n    windows = []\n    for i in range(0, len(lst) - window_size + 1, step_size):\n        windows.append(lst[i:i + window_size])\n    return windows\n\ndef build_index(text, chunk_size, chunk_overlap):\n    '''База текстовых батчей'''\n#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n#     documents = text_splitter.split_documents(\n#         [Document(page_content=text)]\n#     )\n    documents = []\n    for chunk in sliding_window(full_text['chunks'], chunk_size, chunk_overlap):\n        meta_data = (chunk[0]['timestamp'][0], chunk[-1]['timestamp'][0])\n        chunk_text = ' '.join([element['text'] for element in chunk])\n        documents.append(Document(page_content=chunk_text, metadata={'start':meta_data[0], 'end':meta_data[1]}))\n    \n    fixed_documents = [doc for doc in documents if doc]\n    db = Chroma.from_documents(\n        fixed_documents,\n        embeddings,\n        client_settings=Settings(\n            anonymized_telemetry=False\n        ),\n    )\n    return db\n\ndef retrieve(text, db, k_documents):\n    '''Поиск ближайших батчей текста'''\n    context = \"\"\n    if db:\n        retriever = db.as_retriever(search_kwargs={\"k\": k_documents})\n        docs = retriever.get_relevant_documents(text)\n        retrieved_docs = \"\\n\\n\".join([doc.page_content for doc in docs])\n    return retrieved_docs\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:47:19.000554Z","iopub.execute_input":"2023-11-25T05:47:19.000864Z","iopub.status.idle":"2023-11-25T05:47:32.164715Z","shell.execute_reply.started":"2023-11-25T05:47:19.000837Z","shell.execute_reply":"2023-11-25T05:47:32.163878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Метод извлечения терминов","metadata":{}},{"cell_type":"code","source":"# from langchain.llms import YandexGPT\n# import time\n# ygpt = YandexGPT(api_key=\"AQVN0k6NUUf9UZkghayg6kGpyI8tNybqaj58cU60\")\n\n# def exctract_term(text):\n#     output = None\n#     promt = f\"\"\"\n# Найди ключевой термин для которого дано опеределение в данном тексте.\n# Важно: для термина должно быть дано опредление в тексте.\n# Если термин с определением есть, выводи {{термин}}\n# Если термина с определением нет, то выводи {{None}}.\n# Текст:\n# {text}\n# \"\"\"\n#     while True:\n#         time.sleep(3)\n#         try:\n#             output = ygpt(promt, temperature = 0.005)\n#             if output:\n#                 break\n#         except:\n#             continue\n            \n#     return {'system': 'Ты ищешь термин для которого есть определение в тексте','user': promt, 'bot': output}","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:47:32.165854Z","iopub.execute_input":"2023-11-25T05:47:32.166180Z","iopub.status.idle":"2023-11-25T05:47:32.171647Z","shell.execute_reply.started":"2023-11-25T05:47:32.166136Z","shell.execute_reply":"2023-11-25T05:47:32.170826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for document_id in db.get()['ids']:\n#     db._collection.delete(ids=document_id)\n# db.persist()\n# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:47:32.172713Z","iopub.execute_input":"2023-11-25T05:47:32.173003Z","iopub.status.idle":"2023-11-25T05:47:32.469868Z","shell.execute_reply.started":"2023-11-25T05:47:32.172979Z","shell.execute_reply":"2023-11-25T05:47:32.468707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сайга\nn_ctx = 3000 \ntop_k = 40\ntop_p = 0.5\ntemperature = 0.05\nrepeat_penalty = 1.1\n\nROLE_TOKENS = {\n    \"user\": USER_TOKEN,\n    \"bot\": BOT_TOKEN,\n    \"system\": SYSTEM_TOKEN\n}\n\n\ndef get_message_tokens(model, role, content):\n    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n    message_tokens.insert(1, ROLE_TOKENS[role])\n    message_tokens.insert(2, LINEBREAK_TOKEN)\n    message_tokens.append(model.token_eos())\n    return message_tokens\n\n\ndef get_system_tokens(model):\n    system_message = {\n        \"role\": \"system\",\n        \"content\": SYSTEM_PROMPT\n    }\n    return get_message_tokens(model, **system_message)\n\ndef chat_saiga(message, model):\n    system_tokens = get_system_tokens(model)\n    tokens = system_tokens\n    \n    message_tokens = get_message_tokens(model=model, role=\"user\", content=message)\n    role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n    tokens += message_tokens + role_tokens\n    generator = model.generate(\n        tokens,\n        top_k = top_k,\n        top_p = top_p,\n        temp = temperature,\n        repeat_penalty = repeat_penalty,\n        reset = True\n    )\n    \n    result_list = []\n    for token in generator:\n        token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n        tokens.append(token)\n        if token == model.token_eos():\n            break\n        result_list.append(token_str)\n    return ''.join(result_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:47:32.471543Z","iopub.execute_input":"2023-11-25T05:47:32.472342Z","iopub.status.idle":"2023-11-25T05:47:32.546681Z","shell.execute_reply.started":"2023-11-25T05:47:32.472314Z","shell.execute_reply":"2023-11-25T05:47:32.545450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\ntry:\n    del model_s\nexcept:\n    pass\n\nmodel_path = '/kaggle/tmp/model-q4_K.gguf'\nn_ctx = 3000\n\nmodel_s = Llama(\n    model_path = model_path,\n    n_ctx = n_ctx,\n    n_gpu_layers=-1,\n    main_gpu = 1\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T05:47:32.548292Z","iopub.execute_input":"2023-11-25T05:47:32.548673Z","iopub.status.idle":"2023-11-25T05:48:00.140961Z","shell.execute_reply.started":"2023-11-25T05:47:32.548638Z","shell.execute_reply":"2023-11-25T05:48:00.139777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_output(output):\n    output = (re.sub(\"\"\"термин|[\\{\\}:\\n\\r'\"]\"\"\", \"\", output)).split()\n    if len(output) <3 and output:\n        return ' '.join(output)\n    return 'None'\n\ndef exctract_term(text):\n    promt = f\"\"\"\nНайди ключевой термин для которого дано опеределение в данном тексте.\nВажно: для термина должно быть дано опредление в тексте.\nЕсли термин с определением есть, выводи {{термин}}\nЕсли термина с определением нет, то выводи {{None}}.\nТекст:\n{text}\n    \"\"\"\n    with torch.no_grad():\n        output = chat_saiga(promt, model_s)\n    output = clear_output(output)\n    return output","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:20:36.181523Z","iopub.execute_input":"2023-11-25T06:20:36.181966Z","iopub.status.idle":"2023-11-25T06:20:36.188935Z","shell.execute_reply.started":"2023-11-25T06:20:36.181931Z","shell.execute_reply":"2023-11-25T06:20:36.187851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:20:36.686046Z","iopub.execute_input":"2023-11-25T06:20:36.686437Z","iopub.status.idle":"2023-11-25T06:20:36.691601Z","shell.execute_reply.started":"2023-11-25T06:20:36.686405Z","shell.execute_reply":"2023-11-25T06:20:36.690109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ndata_terms = {\"File\":[], 'Term': []}\n\nfiles = os.listdir(\"/kaggle/input/test-data\")\nPATH_TO_AUDIO = \"/kaggle/input/test-data\"\n\nmp3_files = [file for file in files if file.endswith('.mp3')]\n\n# цикл по аудио в папке\nfor audio_file in tqdm(mp3_files):\n    print(f'Работаем в аудио {audio_file}')\n    path_audio_file = f'{PATH_TO_AUDIO}/{audio_file}'\n    with torch.no_grad():\n        audio = librosa.load(path_audio_file, sr=16_000)[0]\n        print('Транскрибируем аудио')\n        full_text = pipe(audio, generate_kwargs={\"language\": \"russian\"})\n    \n    db = build_index(full_text['text'], 10, 5)\n    \n    # ищем список терминов\n    print(f'Ищем список терминов')\n    data = []\n    for batch in tqdm(db.get()['documents']):\n        data.append(exctract_term(batch))\n    \n    data = list(set(data))\n    try:\n        data.remove('None')\n    except:\n        pass\n    \n    data_terms['Term'] += data\n    data_terms['File'] += [audio_file] * len(data)\n    \n    for document_id in db.get()['ids']:\n        db._collection.delete(ids=document_id)\n    db.persist()\n    torch.cuda.empty_cache()\nprint(f'Прошлло времени: {time.time() - start_time}')\nsubmission = pd.DataFrame(data_terms)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:20:37.047289Z","iopub.execute_input":"2023-11-25T06:20:37.048089Z","iopub.status.idle":"2023-11-25T06:49:13.941411Z","shell.execute_reply.started":"2023-11-25T06:20:37.048056Z","shell.execute_reply":"2023-11-25T06:49:13.940405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:44:51.996846Z","iopub.execute_input":"2023-11-24T15:44:51.997820Z","iopub.status.idle":"2023-11-24T15:44:52.003737Z","shell.execute_reply.started":"2023-11-24T15:44:51.997774Z","shell.execute_reply":"2023-11-24T15:44:52.002766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.sort_values(by='File').to_csv('/kaggle/working/sample_submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:54:41.960907Z","iopub.execute_input":"2023-11-25T06:54:41.961729Z","iopub.status.idle":"2023-11-25T06:54:41.969744Z","shell.execute_reply.started":"2023-11-25T06:54:41.961690Z","shell.execute_reply":"2023-11-25T06:54:41.968429Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:53:56.678187Z","iopub.execute_input":"2023-11-25T06:53:56.678610Z","iopub.status.idle":"2023-11-25T06:53:56.691807Z","shell.execute_reply.started":"2023-11-25T06:53:56.678578Z","shell.execute_reply":"2023-11-25T06:53:56.690717Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"           File                             Term\n0    audio2.mp3                              KPI\n1    audio2.mp3                         договора\n2    audio2.mp3                     концентрация\n3    audio2.mp3                 Вершина параболы\n4    audio2.mp3                          Адизесу\n..          ...                              ...\n171  audio1.mp3               SMOKE тестирование\n172  audio1.mp3  Автоматизированные тестирования\n173  audio1.mp3                        iteration\n174  audio1.mp3           Кластеризация дефектов\n175  audio1.mp3                бета-тестирования\n\n[176 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File</th>\n      <th>Term</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio2.mp3</td>\n      <td>KPI</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio2.mp3</td>\n      <td>договора</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio2.mp3</td>\n      <td>концентрация</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio2.mp3</td>\n      <td>Вершина параболы</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio2.mp3</td>\n      <td>Адизесу</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>audio1.mp3</td>\n      <td>SMOKE тестирование</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>audio1.mp3</td>\n      <td>Автоматизированные тестирования</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>audio1.mp3</td>\n      <td>iteration</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>audio1.mp3</td>\n      <td>Кластеризация дефектов</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>audio1.mp3</td>\n      <td>бета-тестирования</td>\n    </tr>\n  </tbody>\n</table>\n<p>176 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%cd /kaggle/working/\n%ls","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:57:11.587991Z","iopub.execute_input":"2023-11-25T06:57:11.588416Z","iopub.status.idle":"2023-11-25T06:57:12.744346Z","shell.execute_reply.started":"2023-11-25T06:57:11.588379Z","shell.execute_reply":"2023-11-25T06:57:12.743192Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"/kaggle/working\nsample_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T06:57:19.520150Z","iopub.execute_input":"2023-11-25T06:57:19.520548Z","iopub.status.idle":"2023-11-25T06:57:19.528152Z","shell.execute_reply.started":"2023-11-25T06:57:19.520514Z","shell.execute_reply":"2023-11-25T06:57:19.527214Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/sample_submission.csv","text/html":"<a href='sample_submission.csv' target='_blank'>sample_submission.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"\"стэк\" == 'стек'","metadata":{"execution":{"iopub.status.busy":"2023-11-24T15:38:52.643761Z","iopub.execute_input":"2023-11-24T15:38:52.644797Z","iopub.status.idle":"2023-11-24T15:38:52.651387Z","shell.execute_reply.started":"2023-11-24T15:38:52.644758Z","shell.execute_reply":"2023-11-24T15:38:52.650406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Соствление коспекта","metadata":{}},{"cell_type":"code","source":"with torch.no_grad():\n    audio = librosa.load(\"/kaggle/input/audiofiles/audio6.mp3\", sr=16_000)[0]\n    full_text = pipe(audio, generate_kwargs={\"language\": \"russian\"})","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:12:22.962755Z","iopub.execute_input":"2023-11-24T20:12:22.963501Z","iopub.status.idle":"2023-11-24T20:13:34.125686Z","shell.execute_reply.started":"2023-11-24T20:12:22.963463Z","shell.execute_reply":"2023-11-24T20:13:34.124708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    for document_id in db.get()['ids']:\n        db._collection.delete(ids=document_id)\n    db.persist()\nexcept:\n    pass\ndb = build_index(full_text['text'], 20, 10)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:14:46.342673Z","iopub.execute_input":"2023-11-24T20:14:46.343044Z","iopub.status.idle":"2023-11-24T20:14:52.822906Z","shell.execute_reply.started":"2023-11-24T20:14:46.343014Z","shell.execute_reply":"2023-11-24T20:14:52.822147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db.get()['documents']","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:14:58.236879Z","iopub.execute_input":"2023-11-24T20:14:58.237839Z","iopub.status.idle":"2023-11-24T20:14:58.246822Z","shell.execute_reply.started":"2023-11-24T20:14:58.237802Z","shell.execute_reply":"2023-11-24T20:14:58.245854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = [\n    \"какое название темы\",\n    \"причина изучать этот курс для студента\",\n    \"какую пользу принесёт данный курс для студента\",\n    \"на что влияет знание этой темы\",\n    \"каких ошибок студент избежит освоив эту тему\",\n    \"почему без данной темы нельзя двигаться дальше в профессии\",\n    \"План данной лекции\"\n]","metadata":{"execution":{"iopub.status.busy":"2023-11-24T17:50:03.628625Z","iopub.execute_input":"2023-11-24T17:50:03.629018Z","iopub.status.idle":"2023-11-24T17:50:03.634509Z","shell.execute_reply.started":"2023-11-24T17:50:03.628986Z","shell.execute_reply":"2023-11-24T17:50:03.633446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"db.get()['documents']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retrieve_text = retrieve(\"каких ошибок студент избежит освоив эту тему\", db, 5)\nretrieve_text","metadata":{"execution":{"iopub.status.busy":"2023-11-24T20:15:08.496932Z","iopub.execute_input":"2023-11-24T20:15:08.497697Z","iopub.status.idle":"2023-11-24T20:15:08.553232Z","shell.execute_reply.started":"2023-11-24T20:15:08.497665Z","shell.execute_reply":"2023-11-24T20:15:08.552345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = \"\"\nfor q in tqdm(questions):\n    retrieve_text = retrieve(q, db, 5)\n    promt = f\"\"\"\nИспользуй текст лекции ответь на ворпос\n{q}?\n\nТекст лекции:\n{retrieve_text}\n    \"\"\"\n    with torch.no_grad():\n        output = chat_saiga(promt, model_s)\n        if output.find('bot')!=-1:\n            output = output[:output.find('bot')]\n            \n        result += output.replace('Выход:', '') +'\\n\\n'","metadata":{"execution":{"iopub.status.busy":"2023-11-24T17:50:03.936261Z","iopub.execute_input":"2023-11-24T17:50:03.936583Z","iopub.status.idle":"2023-11-24T17:51:34.719574Z","shell.execute_reply.started":"2023-11-24T17:50:03.936557Z","shell.execute_reply":"2023-11-24T17:51:34.718620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T17:52:00.041924Z","iopub.execute_input":"2023-11-24T17:52:00.043159Z","iopub.status.idle":"2023-11-24T17:52:00.048646Z","shell.execute_reply.started":"2023-11-24T17:52:00.043111Z","shell.execute_reply":"2023-11-24T17:52:00.047596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"q = \"\"\nretrieve_text = retrieve(q, db, 5)\npromt = f\"\"\"\nИспользуй текст лекции ответь на ворпос\n{q}?\n\nТекст лекции:\n{retrieve_text}\n\"\"\"\nwith torch.no_grad():\n    print(chat_saiga(promt, model_s))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T17:46:08.573787Z","iopub.execute_input":"2023-11-24T17:46:08.574736Z","iopub.status.idle":"2023-11-24T17:46:18.501169Z","shell.execute_reply.started":"2023-11-24T17:46:08.574694Z","shell.execute_reply":"2023-11-24T17:46:18.500121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"terms = []\n\ndef clear_output(output):\n    output = (re.sub(\"\"\"термин|[\\{\\}:\\n\\r'\"]\"\"\", \"\", output)).split()\n    if len(output) <3 and output:\n        return ' '.join(output)\n    return 'None'\n\n\nfor batch in db.get()['documents']:\n    promt = f\"\"\"\nНайди ключевой термин для которого дано опеределение в данном тексте.\nВажно: для термина должно быть дано опредление в тексте.\nЕсли термин с определением есть, выводи {{термин}}\nЕсли термина с определением нет, то выводи {{None}}.\nТекст:\n{batch}\n\"\"\"\n    while True:\n        time.sleep(3)\n        try:\n            output = None\n            print(\"Промт\")\n            print(\"*\"*100)\n            output = chat_saiga(promt, model_s)\n            output = clear_output(output)\n            terms.append(output)\n            print(output)\n            print(\"*\"*100)\n#             print(batch)\n            print(f\"Длина батча: {len(batch)}\")\n            print(\"*\"*100)\n            if output:\n                break\n        except Exceptions as e:\n            print(e)\n            continue","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"terms = list(set(terms))\ntry:\n    terms.remove('None')\nexcept:\n    pass\nterms","metadata":{"execution":{"iopub.status.busy":"2023-11-24T12:55:17.385540Z","iopub.execute_input":"2023-11-24T12:55:17.385814Z","iopub.status.idle":"2023-11-24T12:55:17.393240Z","shell.execute_reply.started":"2023-11-24T12:55:17.385789Z","shell.execute_reply":"2023-11-24T12:55:17.392357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len('input - ')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T13:23:31.809284Z","iopub.execute_input":"2023-11-24T13:23:31.809947Z","iopub.status.idle":"2023-11-24T13:23:31.820467Z","shell.execute_reply.started":"2023-11-24T13:23:31.809917Z","shell.execute_reply":"2023-11-24T13:23:31.819611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for t in terms:\n    chain_prompt = f\"\"\"{t} - это\"\"\"\n    term_text = retrieve(chain_prompt, db, 5)\n    definition_prompt = f\"\"\"\nСоставь определение термину \"{t}\" на основе текста\nВывод должен быть в формате термин - определение\nДай пожалуйста определение термину {t} - \n\nТекст\n{term_text}\n\"\"\"\n    output = chat_saiga(definition_prompt, model_s)\n    print(output)\n    print('*' * 100 )\n    print(output[len(t + ' - '):]) \n#     print(f\"{t} - {output}\")\n#     print(definition_prompt)\n#     while True:\n#         try:\n#             output = chat_saiga(definition_prompt, model_s)\n#             print(f\"{t} - output\")\n#             if output:\n#                 break\n#         except:\n#             continue\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T13:32:19.109628Z","iopub.execute_input":"2023-11-24T13:32:19.110031Z","iopub.status.idle":"2023-11-24T13:33:15.287761Z","shell.execute_reply.started":"2023-11-24T13:32:19.110004Z","shell.execute_reply":"2023-11-24T13:33:15.286717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = [\n    {'user': 12344},\n    {'user': 12344}\n]\nwith open('/kaggle/working/testoviy.json', \"w\", encoding='utf-8') as w:\n    json.dump(data, w, ensure_ascii=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T08:15:04.395499Z","iopub.execute_input":"2023-11-24T08:15:04.395910Z","iopub.status.idle":"2023-11-24T08:15:04.401849Z","shell.execute_reply.started":"2023-11-24T08:15:04.395877Z","shell.execute_reply":"2023-11-24T08:15:04.400779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}