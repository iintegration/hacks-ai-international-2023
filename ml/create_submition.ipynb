{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-25T05:39:39.092853Z","iopub.status.busy":"2023-11-25T05:39:39.092583Z","iopub.status.idle":"2023-11-25T05:45:16.195640Z","shell.execute_reply":"2023-11-25T05:45:16.194236Z","shell.execute_reply.started":"2023-11-25T05:39:39.092829Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install huggingsound\n","!pip install -U transformers\n","!pip install -q ipython-autotime\n","!pip install -q accelerate optimum\n","!pip install moviepy\n","!pip install langchain\n","!pip install chromadb\n","!pip install sentence-transformers\n","!pip install imutils\n","!pip install llama-cpp-python\n","!pip install faiss-cpu\n","!pip install langchain-experimental\n","!pip install yandexcloud"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:45:16.198555Z","iopub.status.busy":"2023-11-25T05:45:16.198231Z","iopub.status.idle":"2023-11-25T05:45:40.548203Z","shell.execute_reply":"2023-11-25T05:45:40.547028Z","shell.execute_reply.started":"2023-11-25T05:45:16.198523Z"},"trusted":true},"outputs":[],"source":["%cd ~\n","!git clone --recursive https://github.com/ggerganov/llama.cpp.git\n","%cd llama.cpp\n","!make LLAMA_CUBLAS=1 -j libllama.so\n","\n","# HACK: Use custom compiled libllama.so\n","%cp ~/llama.cpp/libllama.so /opt/conda/lib/python3.10/site-packages/llama_cpp/libllama.so"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:45:40.549950Z","iopub.status.busy":"2023-11-25T05:45:40.549639Z","iopub.status.idle":"2023-11-25T05:46:01.703575Z","shell.execute_reply":"2023-11-25T05:46:01.702722Z","shell.execute_reply.started":"2023-11-25T05:45:40.549920Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import librosa\n","import time\n","import cv2\n","import imutils\n","import shutil\n","import glob\n","import argparse\n","\n","import numpy as np\n","\n","from collections import defaultdict\n","from pydub import AudioSegment\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    GenerationConfig,\n","    Speech2TextProcessor,\n","    Speech2TextForConditionalGeneration,\n","    Wav2Vec2ForCTC,\n","    Wav2Vec2Processor,\n","    AutoModelForSpeechSeq2Seq, \n","    AutoProcessor, \n","    pipeline\n",")\n","from datasets import load_dataset\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.vectorstores import Chroma\n","from langchain.vectorstores import FAISS\n","from langchain.callbacks.manager import CallbackManagerForLLMRun\n","from langchain.llms.base import LLM\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.docstore.document import Document\n","from chromadb.config import Settings\n","from llama_cpp import Llama\n","\n","from langchain.agents import Tool\n","from langchain.agents import load_tools\n","from langchain.agents import initialize_agent\n","from langchain.agents import AgentType\n","from typing import Any, List, Mapping, Optional\n","from langchain_experimental.agents.agent_toolkits import create_csv_agent\n","import pandas as pd\n","from tqdm import tqdm\n","import json\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:46:01.705250Z","iopub.status.busy":"2023-11-25T05:46:01.704663Z","iopub.status.idle":"2023-11-25T05:46:02.019644Z","shell.execute_reply":"2023-11-25T05:46:02.018688Z","shell.execute_reply.started":"2023-11-25T05:46:01.705222Z"},"trusted":true},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:46:02.022476Z","iopub.status.busy":"2023-11-25T05:46:02.022143Z","iopub.status.idle":"2023-11-25T05:46:29.913643Z","shell.execute_reply":"2023-11-25T05:46:29.912519Z","shell.execute_reply.started":"2023-11-25T05:46:02.022450Z"},"trusted":true},"outputs":[],"source":["%cd /kaggle/\n","!mkdir tmp\n","%cd tmp\n","\n","!wget https://huggingface.co/IlyaGusev/saiga_mistral_7b_gguf/resolve/main/model-q4_K.gguf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:46:29.915333Z","iopub.status.busy":"2023-11-25T05:46:29.915011Z","iopub.status.idle":"2023-11-25T05:46:29.923913Z","shell.execute_reply":"2023-11-25T05:46:29.923048Z","shell.execute_reply.started":"2023-11-25T05:46:29.915303Z"},"trusted":true},"outputs":[],"source":["TRANSCRIBER_ID = \"openai/whisper-large-v2\"\n","\n","# EMBEDDER_ID = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n","EMBEDDER_ID =\"ai-forever/sbert_large_nlu_ru\"\n","\n","\n","FRAME_RATE = 1        \n","WARMUP = FRAME_RATE              \n","FGBG_HISTORY = round(FRAME_RATE * 15)   \n","VAR_THRESHOLD = 16              \n","MIN_PERCENT = 0.1               \n","MAX_PERCENT = 3         \n","\n","SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\"\n","SYSTEM_TOKEN = 1587\n","USER_TOKEN = 2188\n","BOT_TOKEN = 12435\n","LINEBREAK_TOKEN = 13\n","\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","TORCH_DTYPE = torch.float16 if torch.cuda.is_available() else torch.float32\n","\n","print(DEVICE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:46:29.925438Z","iopub.status.busy":"2023-11-25T05:46:29.925130Z","iopub.status.idle":"2023-11-25T05:47:18.998953Z","shell.execute_reply":"2023-11-25T05:47:18.997732Z","shell.execute_reply.started":"2023-11-25T05:46:29.925414Z"},"trusted":true},"outputs":[],"source":["# openai/whisper-large-v2  \n","processor = AutoProcessor.from_pretrained(TRANSCRIBER_ID)\n","model_t = AutoModelForSpeechSeq2Seq.from_pretrained(\n","    TRANSCRIBER_ID, torch_dtype=TORCH_DTYPE, low_cpu_mem_usage=True, use_safetensors=True\n",")\n","model_t.to(DEVICE)\n","\n","pipe = pipeline(\n","    \"automatic-speech-recognition\",\n","    model=model_t,\n","    tokenizer=processor.tokenizer,\n","    feature_extractor=processor.feature_extractor,\n","    max_new_tokens=128,\n","    chunk_length_s=30,\n","    batch_size=16,\n","    return_timestamps=True,\n","    torch_dtype=TORCH_DTYPE,\n","    device=DEVICE,\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:47:19.000864Z","iopub.status.busy":"2023-11-25T05:47:19.000554Z","iopub.status.idle":"2023-11-25T05:47:32.164715Z","shell.execute_reply":"2023-11-25T05:47:32.163878Z","shell.execute_reply.started":"2023-11-25T05:47:19.000837Z"},"trusted":true},"outputs":[],"source":["embeddings = HuggingFaceEmbeddings(model_name=EMBEDDER_ID)\n","\n","# landchain \n","def sliding_window(lst, window_size, step_size):\n","    windows = []\n","    for i in range(0, len(lst) - window_size + 1, step_size):\n","        windows.append(lst[i:i + window_size])\n","    return windows\n","\n","def build_index(text, chunk_size, chunk_overlap):\n","    '''База текстовых батчей'''\n","    documents = []\n","    for chunk in sliding_window(full_text['chunks'], chunk_size, chunk_overlap):\n","        meta_data = (chunk[0]['timestamp'][0], chunk[-1]['timestamp'][0])\n","        chunk_text = ' '.join([element['text'] for element in chunk])\n","        documents.append(Document(page_content=chunk_text, metadata={'start':meta_data[0], 'end':meta_data[1]}))\n","    \n","    fixed_documents = [doc for doc in documents if doc]\n","    db = Chroma.from_documents(\n","        fixed_documents,\n","        embeddings,\n","        client_settings=Settings(\n","            anonymized_telemetry=False\n","        ),\n","    )\n","    return db\n","\n","def retrieve(text, db, k_documents):\n","    '''Поиск ближайших батчей текста'''\n","    context = \"\"\n","    if db:\n","        retriever = db.as_retriever(search_kwargs={\"k\": k_documents})\n","        docs = retriever.get_relevant_documents(text)\n","        retrieved_docs = \"\\n\\n\".join([doc.page_content for doc in docs])\n","    return retrieved_docs\n"]},{"cell_type":"markdown","metadata":{},"source":["# Ф-ия для генерации датасета  \n","Датасет был сгенерирован с помощью YandexGPT, но не удалось дообучить модель Saiga из за нехватки ресурсов и проблем с datasphere.  \n","Предобученная Saiga также хорошо справляется с данной задачей, поэтому дообучение решено оставить на дальнейшее развитие"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain.llms import YandexGPT\n","import time\n","ygpt = YandexGPT(api_key=\"AQVN0k6NUUf9UZkghayg6kGpyI8tNybqaj58cU60\")\n","\n","def exctract_term(text):\n","    output = None\n","    promt = f\"\"\"\n","Найди ключевой термин для которого дано опеределение в данном тексте.\n","Важно: для термина должно быть дано опредление в тексте.\n","Если термин с определением есть, выводи {{термин}}\n","Если термина с определением нет, то выводи {{None}}.\n","Текст:\n","{text}\n","\"\"\"\n","    while True:\n","        time.sleep(3)\n","        try:\n","            output = ygpt(promt, temperature = 0.005)\n","            if output:\n","                break\n","        except:\n","            continue\n","            \n","    return {'system': 'Ты ищешь термин для которого есть определение в тексте','user': promt, 'bot': output}\n","\n","\n","data = exctract_term(text)\n","with open('/kaggle/working/testoviy.json', \"w\", encoding='utf-8') as w:\n","    json.dump(data, w, ensure_ascii=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Метод извлечения терминов"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = [\n","    {'user': 12344},\n","    {'user': 12344}\n","]\n","with open('/kaggle/working/testoviy.json', \"w\", encoding='utf-8') as w:\n","    json.dump(data, w, ensure_ascii=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:47:32.472342Z","iopub.status.busy":"2023-11-25T05:47:32.471543Z","iopub.status.idle":"2023-11-25T05:47:32.546681Z","shell.execute_reply":"2023-11-25T05:47:32.545450Z","shell.execute_reply.started":"2023-11-25T05:47:32.472314Z"},"trusted":true},"outputs":[],"source":["# сайга\n","n_ctx = 3000 \n","top_k = 40\n","top_p = 0.5\n","temperature = 0.05\n","repeat_penalty = 1.1\n","\n","ROLE_TOKENS = {\n","    \"user\": USER_TOKEN,\n","    \"bot\": BOT_TOKEN,\n","    \"system\": SYSTEM_TOKEN\n","}\n","\n","\n","def get_message_tokens(model, role, content):\n","    message_tokens = model.tokenize(content.encode(\"utf-8\"))\n","    message_tokens.insert(1, ROLE_TOKENS[role])\n","    message_tokens.insert(2, LINEBREAK_TOKEN)\n","    message_tokens.append(model.token_eos())\n","    return message_tokens\n","\n","\n","def get_system_tokens(model):\n","    system_message = {\n","        \"role\": \"system\",\n","        \"content\": SYSTEM_PROMPT\n","    }\n","    return get_message_tokens(model, **system_message)\n","\n","def chat_saiga(message, model):\n","    system_tokens = get_system_tokens(model)\n","    tokens = system_tokens\n","    \n","    message_tokens = get_message_tokens(model=model, role=\"user\", content=message)\n","    role_tokens = [model.token_bos(), BOT_TOKEN, LINEBREAK_TOKEN]\n","    tokens += message_tokens + role_tokens\n","    generator = model.generate(\n","        tokens,\n","        top_k = top_k,\n","        top_p = top_p,\n","        temp = temperature,\n","        repeat_penalty = repeat_penalty,\n","        reset = True\n","    )\n","    \n","    result_list = []\n","    for token in generator:\n","        token_str = model.detokenize([token]).decode(\"utf-8\", errors=\"ignore\")\n","        tokens.append(token)\n","        if token == model.token_eos():\n","            break\n","        result_list.append(token_str)\n","    return ''.join(result_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T05:47:32.548673Z","iopub.status.busy":"2023-11-25T05:47:32.548292Z","iopub.status.idle":"2023-11-25T05:48:00.140961Z","shell.execute_reply":"2023-11-25T05:48:00.139777Z","shell.execute_reply.started":"2023-11-25T05:47:32.548638Z"},"trusted":true},"outputs":[],"source":["%%capture\n","try:\n","    del model_s\n","except:\n","    pass\n","\n","model_path = '/kaggle/tmp/model-q4_K.gguf'\n","n_ctx = 3000\n","\n","model_s = Llama(\n","    model_path = model_path,\n","    n_ctx = n_ctx,\n","    n_gpu_layers=-1,\n","    main_gpu = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T06:20:36.181966Z","iopub.status.busy":"2023-11-25T06:20:36.181523Z","iopub.status.idle":"2023-11-25T06:20:36.188935Z","shell.execute_reply":"2023-11-25T06:20:36.187851Z","shell.execute_reply.started":"2023-11-25T06:20:36.181931Z"},"trusted":true},"outputs":[],"source":["def clear_output(output):\n","    output = (re.sub(\"\"\"термин|[\\{\\}:\\n\\r'\"]\"\"\", \"\", output)).split()\n","    if len(output) <3 and output:\n","        return ' '.join(output)\n","    return 'None'\n","\n","def exctract_term(text):\n","    promt = f\"\"\"\n","Найди ключевой термин для которого дано опеределение в данном тексте.\n","Важно: для термина должно быть дано опредление в тексте.\n","Если термин с определением есть, выводи {{термин}}\n","Если термина с определением нет, то выводи {{None}}.\n","Текст:\n","{text}\n","    \"\"\"\n","    with torch.no_grad():\n","        output = chat_saiga(promt, model_s)\n","    output = clear_output(output)\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T06:20:37.048089Z","iopub.status.busy":"2023-11-25T06:20:37.047289Z","iopub.status.idle":"2023-11-25T06:49:13.941411Z","shell.execute_reply":"2023-11-25T06:49:13.940405Z","shell.execute_reply.started":"2023-11-25T06:20:37.048056Z"},"trusted":true},"outputs":[],"source":["start_time = time.time()\n","data_terms = {\"File\":[], 'Term': []}\n","\n","files = os.listdir(\"/kaggle/input/test-data\")\n","PATH_TO_AUDIO = \"/kaggle/input/test-data\"\n","\n","mp3_files = [file for file in files if file.endswith('.mp3')]\n","\n","# цикл по аудио в папке\n","for audio_file in tqdm(mp3_files):\n","    print(f'Работаем в аудио {audio_file}')\n","    path_audio_file = f'{PATH_TO_AUDIO}/{audio_file}'\n","    with torch.no_grad():\n","        audio = librosa.load(path_audio_file, sr=16_000)[0]\n","        print('Транскрибируем аудио')\n","        full_text = pipe(audio, generate_kwargs={\"language\": \"russian\"})\n","    \n","    db = build_index(full_text['text'], 10, 5)\n","    \n","    # ищем список терминов\n","    print(f'Ищем список терминов')\n","    data = []\n","    for batch in tqdm(db.get()['documents']):\n","        data.append(exctract_term(batch))\n","    \n","    data = list(set(data))\n","    try:\n","        data.remove('None')\n","    except:\n","        pass\n","    \n","    data_terms['Term'] += data\n","    data_terms['File'] += [audio_file] * len(data)\n","    \n","    for document_id in db.get()['ids']:\n","        db._collection.delete(ids=document_id)\n","    db.persist()\n","    torch.cuda.empty_cache()\n","print(f'Прошлло времени: {time.time() - start_time}')\n","submission = pd.DataFrame(data_terms)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T06:54:41.961729Z","iopub.status.busy":"2023-11-25T06:54:41.960907Z","iopub.status.idle":"2023-11-25T06:54:41.969744Z","shell.execute_reply":"2023-11-25T06:54:41.968429Z","shell.execute_reply.started":"2023-11-25T06:54:41.961690Z"},"trusted":true},"outputs":[],"source":["submission.sort_values(by='File').to_csv('/kaggle/working/sample_submission.csv', index = False)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T06:57:11.588416Z","iopub.status.busy":"2023-11-25T06:57:11.587991Z","iopub.status.idle":"2023-11-25T06:57:12.744346Z","shell.execute_reply":"2023-11-25T06:57:12.743192Z","shell.execute_reply.started":"2023-11-25T06:57:11.588379Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n","sample_submission.csv\n"]}],"source":["%cd /kaggle/working/\n","%ls"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-11-25T06:57:19.520548Z","iopub.status.busy":"2023-11-25T06:57:19.520150Z","iopub.status.idle":"2023-11-25T06:57:19.528152Z","shell.execute_reply":"2023-11-25T06:57:19.527214Z","shell.execute_reply.started":"2023-11-25T06:57:19.520514Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='sample_submission.csv' target='_blank'>sample_submission.csv</a><br>"],"text/plain":["/kaggle/working/sample_submission.csv"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'sample_submission.csv')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4049180,"sourceId":7041528,"sourceType":"datasetVersion"},{"datasetId":4055850,"sourceId":7048093,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
